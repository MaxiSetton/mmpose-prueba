{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec5a100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf43ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\48113164\\AppData\\Local\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\mmengine\\optim\\optimizer\\zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "source": [
    "from kp_api import KeypointExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae9cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_cfg_path='configs/wholebody_2d_keypoint/rtmpose/cocktail14/rtmw-l_8xb320-270e_cocktail14-384x288.py'\n",
    "kp_ckpt_path='rtmw-dw-x-l_simcc-cocktail14_270e-384x288-20231122.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022a9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import subprocess\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9eb8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: rtmw-dw-x-l_simcc-cocktail14_270e-384x288-20231122.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\48113164\\AppData\\Local\\miniconda3\\envs\\torch-gpu\\lib\\site-packages\\mmengine\\runner\\checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoint extractor model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "kp_extractor=KeypointExtractor(kp_cfg_path, kp_ckpt_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dafd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando script de procesamiento sostenible (uno por uno)...\n",
      "\n",
      "==================== \n",
      "üìÇ Carpeta Remota: train \n",
      "====================\n",
      "üì° Obteniendo lista de archivos remotos de: drive:MyDrive/Kinetics400/train\n",
      "  -> Encontrados 242 archivos tarball.\n",
      "  Se procesar√°n 242 archivos...\n",
      "\n",
      "  --- Procesando archivo 1/242: part_0.tar.gz ---\n",
      "  ‚¨áÔ∏è Descargando: drive:MyDrive/Kinetics400/train/part_0.tar.gz...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import subprocess\n",
    "remote_files_processed=[]\n",
    "PROGRESS_FILE = Path(\"processed_files.txt\")\n",
    "\n",
    "rclone_remote_root = \"drive:MyDrive/Kinetics400\"\n",
    "# Directorio fuente (donde est√°n los .tar.gz)\n",
    "root_targz_local = Path(\"k400_targz_temp\")\n",
    "\n",
    "# Directorio de destino para los VIDEOS (Requisito 1)\n",
    "root_videos = Path(\"k400_videos\")\n",
    "\n",
    "# Directorio de destino para los KEYPOINTS (Requisito 2)\n",
    "root_keypoints_out = Path(\"k400_keypoints\")\n",
    "\n",
    "# Subcarpetas a procesar (igual que en tu script de Bash)\n",
    "sub_folders = ['train', 'val', 'test', 'replacement']\n",
    "\n",
    "# Extensiones de video a buscar despu√©s de extraer\n",
    "VIDEO_EXTENSIONS = {'.mp4', '.avi', '.mkv', '.webm', '.mov'}\n",
    "def load_processed_files():\n",
    "    \"\"\"Carga la lista de archivos ya procesados desde disco.\"\"\"\n",
    "    if PROGRESS_FILE.exists():\n",
    "        with open(PROGRESS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            return set(line.strip() for line in f if line.strip())\n",
    "    return set()\n",
    "\n",
    "def save_processed_file(file_path: str):\n",
    "    \"\"\"Agrega un archivo procesado al registro.\"\"\"\n",
    "    with open(PROGRESS_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(file_path + \"\\n\")\n",
    "def get_remote_file_list(remote_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Usa 'rclone lsf' para listar archivos .tar.gz y .tgz en un directorio remoto.\n",
    "    \"\"\"\n",
    "    print(f\"üì° Obteniendo lista de archivos remotos de: {remote_path}\")\n",
    "    command = [\"rclone\", \"lsf\", \"--files-only\", remote_path]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, capture_output=True, text=True, check=True, encoding='utf-8')\n",
    "        all_files = result.stdout.splitlines()\n",
    "        # Filtrar solo los tarballs\n",
    "        tar_files = [f for f in all_files if f.endswith('.tar.gz') or f.endswith('.tgz')]\n",
    "        print(f\"  -> Encontrados {len(tar_files)} archivos tarball.\")\n",
    "        return tar_files\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå ERROR al listar archivos con rclone: {e.stderr}\")\n",
    "        return []\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå ERROR: 'rclone' no se encuentra. ¬øEst√° instalado y en tu PATH?\")\n",
    "        return []\n",
    "def download_file(remote_file_path: str, local_file_path: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Descarga un SOLO archivo usando 'rclone copyto'.\n",
    "    \"\"\"\n",
    "    print(f\"  ‚¨áÔ∏è Descargando: {remote_file_path}...\")\n",
    "    # Asegurarse de que el directorio local exista\n",
    "    local_file_path.parent.mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "    command = [\"rclone\", \"copyto\", remote_file_path, str(local_file_path)]\n",
    "    \n",
    "    try:\n",
    "        # Usamos capture_output para no llenar la consola con el log de rclone\n",
    "        subprocess.run(command, check=True, capture_output=True)\n",
    "        print(\"  -> Descarga completa.\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"    ‚ùå ERROR al descargar {remote_file_path}: {e.stderr}\")\n",
    "        return False\n",
    "\n",
    "def process_single_tarball(local_tar_path: Path, videos_dir: Path, keypoints_dir: Path):\n",
    "    \"\"\"\n",
    "    Procesa UN solo archivo .tar.gz:\n",
    "    1. Extrae videos.\n",
    "    2. Procesa videos -> .npy.\n",
    "    3. BORRA videos.\n",
    "    \"\"\"\n",
    "    print(f\"  üóúÔ∏è Extrayendo: {local_tar_path.name} a {videos_dir}\")\n",
    "    try:\n",
    "        with tarfile.open(local_tar_path, \"r:gz\") as tar:\n",
    "            tar.extractall(path=videos_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è AVISO: Error al extraer {local_tar_path.name}: {e}. Omitiendo.\")\n",
    "        return\n",
    "\n",
    "    # --- Procesar Videos Extra√≠dos ---\n",
    "    print(f\"  ü§ñ Procesando videos extra√≠dos...\")\n",
    "    extracted_videos = []\n",
    "    for ext in VIDEO_EXTENSIONS:\n",
    "        # Busca solo en la carpeta de videos, no recursivo\n",
    "        extracted_videos.extend(videos_dir.glob(f'*{ext}'))\n",
    "    \n",
    "    if not extracted_videos:\n",
    "        print(\"    -> No se encontraron videos en este tarball.\")\n",
    "        return\n",
    "\n",
    "    for video_path in extracted_videos:\n",
    "        npy_filename = video_path.with_suffix('.npy').name\n",
    "        npy_path = keypoints_dir / npy_filename\n",
    "\n",
    "        if npy_path.exists():\n",
    "            # print(f\"    -> Ya existe, omitiendo: {npy_path.name}\")\n",
    "            pass # Omitir en silencio\n",
    "        else:\n",
    "            try:\n",
    "                # 2. PROCESAR\n",
    "                keypoints_array = kp_extractor.extract_from_video(video_path)\n",
    "                np.save(npy_path, keypoints_array)\n",
    "            except Exception as e:\n",
    "                print(f\"    ERROR al procesar el video {video_path.name}: {e}\")\n",
    "        \n",
    "        # 3. BORRAR VIDEO (¬°Importante para ahorrar espacio!)\n",
    "        try:\n",
    "            os.remove(video_path)\n",
    "        except Exception as e:\n",
    "            print(f\"      AVISO: No se pudo borrar el video {video_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"  ‚úÖ Videos procesados y borrados.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando script de procesamiento sostenible (uno por uno)...\")\n",
    "    start_time = time.time()\n",
    "    processed_files = load_processed_files()\n",
    "\n",
    "    for folder in sub_folders:\n",
    "        print(f\"\\n{'='*20} \\nüìÇ Carpeta Remota: {folder} \\n{'='*20}\")\n",
    "        remote_folder_path = f\"{rclone_remote_root}/{folder}\"\n",
    "        local_targz_dir = root_targz_local / folder\n",
    "        local_videos_dir = root_videos / folder\n",
    "        local_keypoints_dir = root_keypoints_out / folder\n",
    "        \n",
    "        local_targz_dir.mkdir(parents=True, exist_ok=True)\n",
    "        local_videos_dir.mkdir(parents=True, exist_ok=True)\n",
    "        local_keypoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        remote_files = get_remote_file_list(remote_folder_path)\n",
    "        if not remote_files:\n",
    "            print(f\"  No se encontraron archivos en {remote_folder_path}. Omitiendo.\")\n",
    "            continue\n",
    "\n",
    "        total_files = len(remote_files)\n",
    "        print(f\"  Se procesar√°n {total_files} archivos...\")\n",
    "\n",
    "        for i, filename in enumerate(remote_files, 1):\n",
    "            remote_file_path = f\"{remote_folder_path}/{filename}\"\n",
    "\n",
    "            # üîπ SALTAR si ya se proces√≥ antes\n",
    "            if remote_file_path in processed_files:\n",
    "                print(f\"  ‚ö° Ya procesado: {filename}, omitiendo.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n  --- Procesando archivo {i}/{total_files}: {filename} ---\")\n",
    "            local_tar_path = local_targz_dir / filename\n",
    "            \n",
    "            if not download_file(remote_file_path, local_tar_path):\n",
    "                print(\"  Error en descarga. Omitiendo este archivo.\")\n",
    "                continue\n",
    "            \n",
    "            process_single_tarball(local_tar_path, local_videos_dir, local_keypoints_dir)\n",
    "            \n",
    "            try:\n",
    "                os.remove(local_tar_path)\n",
    "                print(f\"  üóëÔ∏è .tar.gz temporal borrado: {local_tar_path.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    AVISO: No se pudo borrar {local_tar_path.name}: {e}\")\n",
    "            \n",
    "            # ‚úÖ Registrar archivo como procesado\n",
    "            save_processed_file(remote_file_path)\n",
    "            processed_files.add(remote_file_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n{'='*20}\\nüéâ ¬°Proceso completo! \\n{'='*20}\")\n",
    "    print(f\"Directorio de Keypoints: {root_keypoints_out.resolve()}\")\n",
    "    print(f\"Tiempo total: {end_time - start_time:.2f} segundos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057faaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
